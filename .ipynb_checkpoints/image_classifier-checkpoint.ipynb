{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Language Recognition and Translation\n",
    "\n",
    "## NLP-BhaskarjyotiDas Class of 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01FB15ECS285 - Shreyas Miraj\n",
    "### 01FB15ECS290 - Siddharth Ganesan"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset consist of lexical representation of American Sign Language in image format. Multiple images from different users are present.\n",
    "\n",
    "This was the best dataset we could find to train our models, \n",
    "work in this summer will be oriented towards extending the functionality to datasets containing videos of gesture which represent phrases instead of just lexical(alphabetical) representation.\n",
    "\n",
    "\n",
    "Methodology:\n",
    "    1. Image Preprocessing\n",
    "         Hand Region Segmentation\n",
    "         Chromatic Adjustments\n",
    "         Histogram of Oriented Gradiation Representation\n",
    "    2. Using HOG image input as feature for the learner.\n",
    "    3. Building a multiclass classifier with HOG feature vector.\n",
    "    4. Steps to improve the classifier accuracy.\n",
    "    5. Testing the model accuracy\n",
    "    \n",
    "    Language Model\n",
    "    \n",
    "    7. Spell checking to eliminate the errors from the gesture\n",
    "       classifier\n",
    "    8. Enhancing the model output based on input sentiment.\n",
    "   \n",
    "   (Future work)\n",
    "    9. Use the sentiment obtained from the images to bias the\n",
    "       language model, representation is given in the ppt. This\n",
    "       further will be improved upon by using emotion and speed\n",
    "       vector as the added feature input to a CNN image classifier.\n",
    "\n",
    "This is a percursor to the final goal of this project which involves sentiment bias to the output of the gesture recognition system, since most reviews on the existing systems have mentioned about the lack of body language and emotion reading when it comes to sign language translation. Hopefully we can get our hands on a gesture rich video dataset so that we can continue the work in this summer and be able to develop a better system which caters to the what the current models are lacking in.\n",
    "\n",
    "This is not the final stage of the project, due to the complexity involved in the project it cannot be accomplished in a single semester. We will continue working on this through the summer and probably will require another half semester to come up with a fruitful output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, io, filters\n",
    "from skimage.transform import rescale\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog \n",
    "from skimage.transform import resize\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import csv\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import json\n",
    "import time\n",
    "import gzip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Processing and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#given a list of filenames return s a dictionary of images \n",
    "def getfiles(filenames):\n",
    "    dir_files = {}\n",
    "    for x in filenames:\n",
    "        dir_files[x]=io.imread(x)\n",
    "    return dir_files\n",
    "\n",
    "#return hog of a particular image vector\n",
    "def convertToGrayToHOG(imgVector):\n",
    "    rgbImage = rgb2gray(imgVector)\n",
    "    return hog(rgbImage)\n",
    "\n",
    "#takes returns cropped image \n",
    "def crop(img,x1,x2,y1,y2):\n",
    "    crp=img[y1:y2,x1:x2]\n",
    "    crp=resize(crp,((128,128)))#resize\n",
    "    return crp\n",
    "\n",
    "#save classifier\n",
    "def dumpclassifier(filename,model):\n",
    "    with open(filename, 'wb') as fid:\n",
    "        pickle.dump(model, fid)    \n",
    "\n",
    "#load classifier\n",
    "def loadClassifier(picklefile):\n",
    "    fd = open(picklefile, 'r+')\n",
    "    model = pickle.load(fd)\n",
    "    fd.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This function randomly generates bounding boxes \n",
    "Return: hog vector of those cropped bounding boxes along with label \n",
    "Label : 1 if hand ,0 otherwise \n",
    "\"\"\"\n",
    "def buildhandnothand_lis(frame,imgset):\n",
    "    poslis =[]\n",
    "    neglis =[]\n",
    "\n",
    "    for nameimg in frame.image:\n",
    "        tupl = frame[frame['image']==nameimg].values[0]\n",
    "        x_tl = tupl[1]\n",
    "        y_tl = tupl[2]\n",
    "        side = tupl[5]\n",
    "        conf = 0\n",
    "        \n",
    "        dic = [0, 0]\n",
    "        \n",
    "        arg1 = [x_tl,y_tl,conf,side,side]\n",
    "        poslis.append(convertToGrayToHOG(crop(imgset[nameimg],x_tl,x_tl+side,y_tl,y_tl+side)))\n",
    "        while dic[0] <= 1 or dic[1] < 1:\n",
    "            x = random.randint(0,320-side)\n",
    "            y = random.randint(0,240-side) \n",
    "            crp = crop(imgset[nameimg],x,x+side,y,y+side)\n",
    "            hogv = convertToGrayToHOG(crp)\n",
    "            arg2 = [x,y, conf, side, side]\n",
    "            \n",
    "            z = overlapping_area(arg1,arg2)\n",
    "            if dic[0] <= 1 and z <= 0.5:\n",
    "                neglis.append(hogv)\n",
    "                dic[0] += 1\n",
    "            if dic[0]== 1:\n",
    "                break\n",
    "    label_1 = [1 for i in range(0,len(poslis)) ]\n",
    "    label_0 = [0 for i in range(0,len(neglis))]\n",
    "    label_1.extend(label_0)\n",
    "    poslis.extend(neglis)\n",
    "    return poslis,label_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns imageset and bounding box for a list of users \n",
    "def train_binary(train_list, data_directory):\n",
    "    frame = pd.DataFrame()\n",
    "    list_ = []\n",
    "    for user in train_list:\n",
    "        list_.append(pd.read_csv(data_directory+user+'/'+user+'_loc.csv',index_col=None,header=0))\n",
    "    frame = pd.concat(list_)\n",
    "    frame['side']=frame['bottom_right_x']-frame['top_left_x']\n",
    "    frame['hand']=1\n",
    "\n",
    "    imageset = getfiles(frame.image.unique())\n",
    "\n",
    "    #returns actual images and dataframe \n",
    "    return imageset,frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads data for binary classification (hand/not-hand)\n",
    "def load_binary_data(user_list, data_directory):\n",
    "    data1,df  =train_binary(user_list, data_directory) # data 1 - actual images , df is actual bounding box\n",
    "    \n",
    "    # third return, i.e., z is a list of hog vecs, labels\n",
    "    z = buildhandnothand_lis(df,data1)\n",
    "    return data1,df,z[0],z[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads data for multiclass \n",
    "def get_data(user_list, img_dict, data_directory):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for user in user_list:\n",
    "        user_images = glob.glob(data_directory+user+'/*.jpg')\n",
    "\n",
    "        boundingbox_df = pd.read_csv(data_directory+user+'/'+user+'_loc.csv')\n",
    "        \n",
    "        for rows in boundingbox_df.iterrows():\n",
    "            cropped_img = crop(img_dict[rows[1]['image']], rows[1]['top_left_x'], rows[1]['bottom_right_x'], rows[1]['top_left_y'], rows[1]['bottom_right_y'])\n",
    "            hogvector = convertToGrayToHOG(cropped_img)\n",
    "            X.append(hogvector.tolist())\n",
    "            Y.append(rows[1]['image'].split('/')[1][0])\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility funtcion to compute area of overlap\n",
    "def overlapping_area(detection_1, detection_2):\n",
    "    x1_tl = detection_1[0]\n",
    "    x2_tl = detection_2[0]\n",
    "    x1_br = detection_1[0] + detection_1[3]\n",
    "    x2_br = detection_2[0] + detection_2[3]\n",
    "    y1_tl = detection_1[1]\n",
    "    y2_tl = detection_2[1]\n",
    "    y1_br = detection_1[1] + detection_1[4]\n",
    "    y2_br = detection_2[1] + detection_2[4]\n",
    "    # Calculate the overlapping Area\n",
    "    x_overlap = max(0, min(x1_br, x2_br)-max(x1_tl, x2_tl))\n",
    "    y_overlap = max(0, min(y1_br, y2_br)-max(y1_tl, y2_tl))\n",
    "    overlap_area = x_overlap * y_overlap\n",
    "    area_1 = detection_1[3] * detection_2[4]\n",
    "    area_2 = detection_2[3] * detection_2[4]\n",
    "    total_area = area_1 + area_2 - overlap_area\n",
    "    return overlap_area / float(total_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Does hard negative mining and returns list of hog vectos , label list and no_of_false_positives after sliding \n",
    "\"\"\"\n",
    "def do_hardNegativeMining(cached_window,frame, imgset, model, step_x, step_y):   \n",
    "    lis = []\n",
    "    no_of_false_positives = 0\n",
    "    for nameimg in frame.image:\n",
    "        tupl = frame[frame['image']==nameimg].values[0]\n",
    "        x_tl = tupl[1]\n",
    "        y_tl = tupl[2]\n",
    "        side = tupl[5]\n",
    "        conf = 0\n",
    "        \n",
    "        dic = [0, 0]\n",
    "        \n",
    "        arg1 = [x_tl,y_tl,conf,side,side]\n",
    "        for x in range(0,320-side,step_x):\n",
    "            for y in range(0,240-side,step_y):\n",
    "                arg2 = [x,y,conf,side,side]\n",
    "                z = overlapping_area(arg1,arg2)\n",
    "                \n",
    "                \n",
    "                prediction = model.predict([cached_window[str(nameimg)+str(x)+str(y)]])[0]\n",
    "\n",
    "                if prediction == 1 and z<=0.5:\n",
    "                    lis.append(cached_window[str(nameimg)+str(x)+str(y)])\n",
    "                    no_of_false_positives += 1\n",
    "    \n",
    "    label = [0 for i in range(0,len(lis))]\n",
    "    return lis,label, no_of_false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Modifying to cache image values before hand so as to not redo that again and again \n",
    "\n",
    "\"\"\"\n",
    "def cacheSteps(imgset, frame ,step_x,step_y):\n",
    "    # print \"Cache-ing steps\"\n",
    "    list_dic_of_hogs = []\n",
    "    dic = {}\n",
    "    i = 0\n",
    "    for img in frame.image:\n",
    "        tupl = frame[frame['image']==img].values[0]\n",
    "        x_tl = tupl[1]\n",
    "        y_tl = tupl[2]\n",
    "        side = tupl[5]\n",
    "        conf = 0\n",
    "        i += 1 \n",
    "        # if i%10 == 0:\n",
    "        #     print \"{0} images cached \".format(i)\n",
    "        imaage = imgset[img]\n",
    "        for x in range(0,320-side,step_x):\n",
    "            for y in range(0,240-side,step_y):\n",
    "                dic[str(img+str(x)+str(y))]=convertToGrayToHOG(crop(imaage,x,x+side,y,y+side))\n",
    "    return dic    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def improve_Classifier_using_HNM(hog_list, label_list, frame, imgset, threshold=50, max_iterations=25): # frame - bounding boxes-df; yn_df - yes_or_no df\n",
    "    # print \"Performing HNM :\"\n",
    "    no_of_false_positives = 1000000     # Initialise to some random high value\n",
    "    i = 0\n",
    "\n",
    "    step_x = 32\n",
    "    step_y = 24\n",
    "\n",
    "    mnb  = MultinomialNB()\n",
    "    cached_wind = cacheSteps(imgset, frame, step_x, step_y)\n",
    "\n",
    "    while True:\n",
    "        i += 1\n",
    "        model = mnb.partial_fit(hog_list, label_list, classes = [0,1])\n",
    "\n",
    "        ret = do_hardNegativeMining(cached_wind,frame, imgset, model, step_x=step_x, step_y=step_y)\n",
    "        \n",
    "        hog_list = ret[0]\n",
    "        label_list = ret[1]\n",
    "        no_of_false_positives = ret[2]\n",
    "        \n",
    "        if no_of_false_positives == 0:\n",
    "            return model\n",
    "        \n",
    "        print \"Iteration {0} - No_of_false_positives: {1}\".format(i, no_of_false_positives) \n",
    "        \n",
    "        if no_of_false_positives <= threshold:\n",
    "            return model\n",
    "        \n",
    "        if i>max_iterations:\n",
    "             return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Malisiewicz et al.\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    # print \"Perfmorinf NMS:\"\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    " \n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    " \n",
    "    # initialize the list of picked indexes \n",
    "    pick = []\n",
    "\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    s = boxes[:,4]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(s)\n",
    "\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return boxes[pick].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the tuple with the highest prediction probability of hand\n",
    "def image_pyramid_step(model, img, scale=1.0):\n",
    "    max_confidence_seen = -1\n",
    "    rescaled_img = rescale(img, scale)\n",
    "    detected_box = []\n",
    "    side = 128\n",
    "    x_border = rescaled_img.shape[1]\n",
    "    y_border = rescaled_img.shape[0]\n",
    " \n",
    "    for x in range(0,x_border-side,32):\n",
    "        for y in range(0,y_border-side,24):\n",
    "            cropped_img = crop(rescaled_img,x,x+side,y,y+side)\n",
    "            hogvector = convertToGrayToHOG(cropped_img)\n",
    "\n",
    "            confidence = model.predict_proba([hogvector])\n",
    "\n",
    "            if confidence[0][1] > max_confidence_seen:\n",
    "                detected_box = [x, y, confidence[0][1], scale]\n",
    "                max_confidence_seen = confidence[0][1]\n",
    "\n",
    "    return detected_box\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Class for gesturerecognizer(themodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=================================================================================================================================\n",
    "\"\"\"\n",
    "\n",
    "class GestureRecognizer(object):\n",
    "    \"\"\"class to perform gesture recognition\"\"\"\n",
    "\n",
    "    def __init__(self, data_director='./'):\n",
    "        \"\"\"\n",
    "            data_directory : path like /home/sanket/mlproj/dataset/    \n",
    "            includes the dataset folder with '/'\n",
    "            Initialize all your variables here\n",
    "        \"\"\"\n",
    "        self.data_directory = data_director\n",
    "        self.handDetector = None\n",
    "        self.signDetector = None\n",
    "        self.label_encoder = LabelEncoder().fit(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N',\n",
    "       'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y'])\n",
    "\n",
    "    def train(self, train_list):\n",
    "        \"\"\"\n",
    "            train_list : list of users to use for training\n",
    "            eg [\"user_1\", \"user_2\", \"user_3\"]\n",
    "            The train function should train all your classifiers\n",
    "            both binary and multiclass on the given list of users\n",
    "        \"\"\"\n",
    "        print \"Train starts\"\n",
    "        # Load data for the binary (hand/not hand) classification task\n",
    "        imageset, boundbox, hog_list, label_list = load_binary_data(train_list, self.data_directory)\n",
    "\n",
    "        print \"Imageset, boundbox, hog_list,label_list Loaded!\"\n",
    "\n",
    "        # Load data for the multiclass classification task\n",
    "        X_mul,Y_mul = get_data(train_list, imageset, self.data_directory)\n",
    "\n",
    "        print \"Multiclass data loaded\"\n",
    "       \n",
    "\n",
    "        Y_mul = self.label_encoder.fit_transform(Y_mul)\n",
    "\n",
    "        if self.handDetector == None:\n",
    "            # Build binary classifier for hand-nothand classification\n",
    "            self.handDetector = improve_Classifier_using_HNM(hog_list, label_list, boundbox, imageset, threshold=40, max_iterations=35)\n",
    "\n",
    "        print \"handDetector trained \"\n",
    "\n",
    "        # Multiclass classification part to classify the various signs/hand gestures CHECK. TODO.\n",
    "        \n",
    "        if self.signDetector == None:\n",
    "            svcmodel = SVC(kernel='linear', C=0.9, probability=True)\n",
    "            self.signDetector = svcmodel.fit(X_mul, Y_mul)\n",
    "\n",
    "\n",
    "        print \"sign Detector trained \"\n",
    "\n",
    "        # dumpclassifier('handDetector.pkl', self.handDetector)\n",
    "        \n",
    "        # dumpclassifier('signDetector.pkl', self.signDetector)\n",
    "\n",
    "        # dumpclassifier('label_encoder.pkl', self.label_encoder)\n",
    "\n",
    "\n",
    "    def recognize_gesture(self, image):\n",
    "        \"\"\"\n",
    "            image : a 320x240 pixel RGB image in the form of a numpy array\n",
    "\n",
    "            This function should locate the hand and classify the gesture.\n",
    "            returns : (position, label)\n",
    "\n",
    "            position : a tuple of (x1,y1,x2,y2) coordinates of bounding box\n",
    "                x1,y1 is top left corner, x2,y2 is bottom right\n",
    "\n",
    "            label : a single character. eg 'A' or 'B'\n",
    "        \"\"\"\n",
    "        # print \"In recognize_gesture\"\n",
    "        scales = [   1.25,\n",
    "                 1.015625,\n",
    "                 0.78125,\n",
    "                 0.546875,\n",
    "                 1.5625,\n",
    "                 1.328125,\n",
    "                 1.09375,\n",
    "                 0.859375,\n",
    "                 0.625,\n",
    "                 1.40625,\n",
    "                 1.171875,\n",
    "                 0.9375,\n",
    "                 0.703125,\n",
    "                 1.71875,\n",
    "                 1.484375\n",
    "            ]\n",
    "\n",
    "        detectedBoxes = [] ## [x,y,conf,scale]\n",
    "        for sc in scales:\n",
    "            detectedBoxes.append(image_pyramid_step(self.handDetector,image,scale=sc))\n",
    "        \n",
    "        side = [0 for i in xrange(len(scales))]\n",
    "        for i in xrange(len(scales)):\n",
    "            side[i]= 128/scales[i]\n",
    "\n",
    "        for i in xrange(len(detectedBoxes)):\n",
    "            detectedBoxes[i][0]=detectedBoxes[i][0]/scales[i] #x\n",
    "            detectedBoxes[i][1]=detectedBoxes[i][1]/scales[i] #y\n",
    "\n",
    "        nms_lis = [] #[x1,x2,y1,y2]\n",
    "        for i in xrange(len(detectedBoxes)):\n",
    "            nms_lis.append([detectedBoxes[i][0],detectedBoxes[i][1],\n",
    "                            detectedBoxes[i][0]+side[i],detectedBoxes[i][1]+side[i],detectedBoxes[i][2]])\n",
    "        nms_lis = np.array(nms_lis)\n",
    "\n",
    "        res = non_max_suppression_fast(nms_lis,0.4)\n",
    "\n",
    "        output_det = res[0]\n",
    "        x_top = output_det[0]\n",
    "        y_top = output_det[1]\n",
    "        side = output_det[2]-output_det[0]\n",
    "        position = [x_top, y_top, x_top+side, y_top+side]\n",
    "        \n",
    "        croppedImage = crop(image, x_top, x_top+side, y_top, y_top+side)\n",
    "        hogvec = convertToGrayToHOG(croppedImage)\n",
    "\n",
    "        prediction = self.signDetector.predict_proba([hogvec])[0]\n",
    "\n",
    "        zi = zip(self.signDetector.classes_, prediction)\n",
    "        zi.sort(key = lambda x:x[1],reverse = True)\n",
    "        \n",
    "        # To return the top 5 predictions\n",
    "        final_prediction = []\n",
    "        for i in range(5):\n",
    "            final_prediction.append(self.label_encoder.inverse_transform(zi[i][0]))\n",
    "        # print position,final_prediction\n",
    "\n",
    "        return position,final_prediction\n",
    "        \n",
    "    def save_model(self, **params):\n",
    "\n",
    "        \"\"\"\n",
    "            save your GestureRecognizer to disk.\n",
    "        \"\"\"\n",
    "\n",
    "        self.version = params['version']\n",
    "        self.author = params['author']\n",
    "\n",
    "        file_name = params['name']\n",
    "\n",
    "        pickle.dump(self, gzip.open(file_name, 'wb'))\n",
    "        # We are using gzip to compress the file\n",
    "        # If you feel compression is not needed, kindly take lite\n",
    "\n",
    "    @staticmethod       # similar to static method in Java\n",
    "    def load_model(**params):\n",
    "        \"\"\"\n",
    "            Returns a saved instance of GestureRecognizer.\n",
    "\n",
    "            load your trained GestureRecognizer from disk with provided params\n",
    "            Read - http://stackoverflow.com/questions/36901/what-does-double-star-and-star-do-for-parameters\n",
    "        \"\"\"\n",
    "\n",
    "        file_name = params['name']\n",
    "        return pickle.load(gzip.open(file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# userlist represents the dataset being read\n",
    "userlist=['user_3','user_4','user_5','user_6','user_7','user_9','user_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thepilot/scikit-image/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/thepilot/scikit-image/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/home/thepilot/scikit-image/skimage/feature/_hog.py:150: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15. To supress this message specify explicitly the normalization method.\n",
      "  skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imageset, boundbox, hog_list,label_list Loaded!\n",
      "Multiclass data loaded\n",
      "Iteration 1 - No_of_false_positives: 901\n",
      "Iteration 2 - No_of_false_positives: 1961\n",
      "Iteration 3 - No_of_false_positives: 2161\n",
      "Iteration 4 - No_of_false_positives: 1132\n",
      "Iteration 5 - No_of_false_positives: 144\n",
      "Iteration 6 - No_of_false_positives: 103\n",
      "Iteration 7 - No_of_false_positives: 80\n",
      "Iteration 8 - No_of_false_positives: 70\n",
      "Iteration 9 - No_of_false_positives: 57\n",
      "Iteration 10 - No_of_false_positives: 50\n",
      "Iteration 11 - No_of_false_positives: 42\n",
      "Iteration 12 - No_of_false_positives: 36\n",
      "handDetector trained \n",
      "sign Detector trained \n",
      "The GestureRecognizer is saved to disk\n"
     ]
    }
   ],
   "source": [
    "#DO NOT RUN THIS IF THE MODEL IS SAVED ALREADY\n",
    "#Training out the model\n",
    "\n",
    "gs = GestureRecognizer('/home/thepilot/Documents/PES/CSE_VI/NLP/NaturalLanguageProcessing/Project/01FB15ECS285_01FB15ECS290/dataset/')\n",
    "user_tr = userlist[:1]\n",
    "user_te = userlist[-1:]\n",
    "gs.train(user_tr)\n",
    "\n",
    "#saving model to avoid repeated run of the trainer.\n",
    "gs.save_model(name = \"sign_detector.pkl.gz\", version = \"0.0.1\", author = 'ss')\n",
    "  \n",
    "print \"The GestureRecognizer is saved to disk\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THIS ONLY IF YOU HAVE A SAVED MODEL\n",
    "gs = GestureRecognizer.load_model(name = \"sign_detector.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = io.imread('user_3/G4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thepilot/scikit-image/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([168, 54, 265, 151], ['G', 'T', 'H', 'M', 'X'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.recognize_gesture(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing with image sequence PRETTY from user_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('recognising image: ', 'user_3/P3.jpg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('top_5 predicted classes: ', ['Q', 'P', 'X', 'T', 'R'])\n",
      "('recognising image: ', 'user_3/R5.jpg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('top_5 predicted classes: ', ['R', 'M', 'N', 'K', 'U'])\n",
      "('recognising image: ', 'user_3/E5.jpg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('top_5 predicted classes: ', ['E', 'M', 'I', 'K', 'N'])\n",
      "('recognising image: ', 'user_3/T8.jpg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('top_5 predicted classes: ', ['T', 'M', 'Q', 'X', 'O'])\n",
      "('recognising image: ', 'user_3/T0.jpg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('top_5 predicted classes: ', ['T', 'M', 'N', 'X', 'O'])\n",
      "('recognising image: ', 'user_3/Y7.jpg')\n",
      "('top_5 predicted classes: ', ['Y', 'I', 'N', 'E', 'S'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#feeding a sequence of images to the classifier that should say PRETTY\n",
    "test_input_array = ['user_3/P3.jpg','user_3/R5.jpg','user_3/E5.jpg','user_3/T8.jpg','user_3/T0.jpg','user_3/Y7.jpg']\n",
    "\n",
    "\n",
    "probable_output = []\n",
    "for test_im in test_input_array:\n",
    "    img = io.imread(test_im)\n",
    "    print(\"recognising image: \",test_im)\n",
    "    pos, val = gs.recognize_gesture(img)\n",
    "    print(\"top_5 predicted classes: \",val)\n",
    "    probable_output.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Q', 'P', 'X', 'T', 'R'],\n",
       " ['R', 'M', 'N', 'K', 'U'],\n",
       " ['E', 'M', 'I', 'K', 'N'],\n",
       " ['T', 'M', 'Q', 'X', 'O'],\n",
       " ['T', 'M', 'N', 'X', 'O'],\n",
       " ['Y', 'I', 'N', 'E', 'S']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probable_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qretty',\n",
       " 'qretti',\n",
       " 'qrettn',\n",
       " 'qrette',\n",
       " 'qretts',\n",
       " 'qretmy',\n",
       " 'qretmi',\n",
       " 'qretmn',\n",
       " 'qretme',\n",
       " 'qretms',\n",
       " 'qretny',\n",
       " 'qretni',\n",
       " 'qretnn',\n",
       " 'qretne',\n",
       " 'qretns',\n",
       " 'qretxy',\n",
       " 'qretxi',\n",
       " 'qretxn',\n",
       " 'qretxe',\n",
       " 'qretxs',\n",
       " 'qretoy',\n",
       " 'qretoi',\n",
       " 'qreton',\n",
       " 'qretoe',\n",
       " 'qretos',\n",
       " 'qremty',\n",
       " 'qremti',\n",
       " 'qremtn',\n",
       " 'qremte',\n",
       " 'qremts',\n",
       " 'qremmy',\n",
       " 'qremmi',\n",
       " 'qremmn',\n",
       " 'qremme',\n",
       " 'qremms',\n",
       " 'qremny',\n",
       " 'qremni',\n",
       " 'qremnn',\n",
       " 'qremne',\n",
       " 'qremns',\n",
       " 'qremxy',\n",
       " 'qremxi',\n",
       " 'qremxn',\n",
       " 'qremxe',\n",
       " 'qremxs',\n",
       " 'qremoy',\n",
       " 'qremoi',\n",
       " 'qremon',\n",
       " 'qremoe',\n",
       " 'qremos',\n",
       " 'qreqty',\n",
       " 'qreqti',\n",
       " 'qreqtn',\n",
       " 'qreqte',\n",
       " 'qreqts',\n",
       " 'qreqmy',\n",
       " 'qreqmi',\n",
       " 'qreqmn',\n",
       " 'qreqme',\n",
       " 'qreqms',\n",
       " 'qreqny',\n",
       " 'qreqni',\n",
       " 'qreqnn',\n",
       " 'qreqne',\n",
       " 'qreqns',\n",
       " 'qreqxy',\n",
       " 'qreqxi',\n",
       " 'qreqxn',\n",
       " 'qreqxe',\n",
       " 'qreqxs',\n",
       " 'qreqoy',\n",
       " 'qreqoi',\n",
       " 'qreqon',\n",
       " 'qreqoe',\n",
       " 'qreqos',\n",
       " 'qrexty',\n",
       " 'qrexti',\n",
       " 'qrextn',\n",
       " 'qrexte',\n",
       " 'qrexts',\n",
       " 'qrexmy',\n",
       " 'qrexmi',\n",
       " 'qrexmn',\n",
       " 'qrexme',\n",
       " 'qrexms',\n",
       " 'qrexny',\n",
       " 'qrexni',\n",
       " 'qrexnn',\n",
       " 'qrexne',\n",
       " 'qrexns',\n",
       " 'qrexxy',\n",
       " 'qrexxi',\n",
       " 'qrexxn',\n",
       " 'qrexxe',\n",
       " 'qrexxs',\n",
       " 'qrexoy',\n",
       " 'qrexoi',\n",
       " 'qrexon',\n",
       " 'qrexoe',\n",
       " 'qrexos',\n",
       " 'qreoty',\n",
       " 'qreoti',\n",
       " 'qreotn',\n",
       " 'qreote',\n",
       " 'qreots',\n",
       " 'qreomy',\n",
       " 'qreomi',\n",
       " 'qreomn',\n",
       " 'qreome',\n",
       " 'qreoms',\n",
       " 'qreony',\n",
       " 'qreoni',\n",
       " 'qreonn',\n",
       " 'qreone',\n",
       " 'qreons',\n",
       " 'qreoxy',\n",
       " 'qreoxi',\n",
       " 'qreoxn',\n",
       " 'qreoxe',\n",
       " 'qreoxs',\n",
       " 'qreooy',\n",
       " 'qreooi',\n",
       " 'qreoon',\n",
       " 'qreooe',\n",
       " 'qreoos',\n",
       " 'qrmtty',\n",
       " 'qrmtti',\n",
       " 'qrmttn',\n",
       " 'qrmtte',\n",
       " 'qrmtts',\n",
       " 'qrmtmy',\n",
       " 'qrmtmi',\n",
       " 'qrmtmn',\n",
       " 'qrmtme',\n",
       " 'qrmtms',\n",
       " 'qrmtny',\n",
       " 'qrmtni',\n",
       " 'qrmtnn',\n",
       " 'qrmtne',\n",
       " 'qrmtns',\n",
       " 'qrmtxy',\n",
       " 'qrmtxi',\n",
       " 'qrmtxn',\n",
       " 'qrmtxe',\n",
       " 'qrmtxs',\n",
       " 'qrmtoy',\n",
       " 'qrmtoi',\n",
       " 'qrmton',\n",
       " 'qrmtoe',\n",
       " 'qrmtos',\n",
       " 'qrmmty',\n",
       " 'qrmmti',\n",
       " 'qrmmtn',\n",
       " 'qrmmte',\n",
       " 'qrmmts',\n",
       " 'qrmmmy',\n",
       " 'qrmmmi',\n",
       " 'qrmmmn',\n",
       " 'qrmmme',\n",
       " 'qrmmms',\n",
       " 'qrmmny',\n",
       " 'qrmmni',\n",
       " 'qrmmnn',\n",
       " 'qrmmne',\n",
       " 'qrmmns',\n",
       " 'qrmmxy',\n",
       " 'qrmmxi',\n",
       " 'qrmmxn',\n",
       " 'qrmmxe',\n",
       " 'qrmmxs',\n",
       " 'qrmmoy',\n",
       " 'qrmmoi',\n",
       " 'qrmmon',\n",
       " 'qrmmoe',\n",
       " 'qrmmos',\n",
       " 'qrmqty',\n",
       " 'qrmqti',\n",
       " 'qrmqtn',\n",
       " 'qrmqte',\n",
       " 'qrmqts',\n",
       " 'qrmqmy',\n",
       " 'qrmqmi',\n",
       " 'qrmqmn',\n",
       " 'qrmqme',\n",
       " 'qrmqms',\n",
       " 'qrmqny',\n",
       " 'qrmqni',\n",
       " 'qrmqnn',\n",
       " 'qrmqne',\n",
       " 'qrmqns',\n",
       " 'qrmqxy',\n",
       " 'qrmqxi',\n",
       " 'qrmqxn',\n",
       " 'qrmqxe',\n",
       " 'qrmqxs',\n",
       " 'qrmqoy',\n",
       " 'qrmqoi',\n",
       " 'qrmqon',\n",
       " 'qrmqoe',\n",
       " 'qrmqos',\n",
       " 'qrmxty',\n",
       " 'qrmxti',\n",
       " 'qrmxtn',\n",
       " 'qrmxte',\n",
       " 'qrmxts',\n",
       " 'qrmxmy',\n",
       " 'qrmxmi',\n",
       " 'qrmxmn',\n",
       " 'qrmxme',\n",
       " 'qrmxms',\n",
       " 'qrmxny',\n",
       " 'qrmxni',\n",
       " 'qrmxnn',\n",
       " 'qrmxne',\n",
       " 'qrmxns',\n",
       " 'qrmxxy',\n",
       " 'qrmxxi',\n",
       " 'qrmxxn',\n",
       " 'qrmxxe',\n",
       " 'qrmxxs',\n",
       " 'qrmxoy',\n",
       " 'qrmxoi',\n",
       " 'qrmxon',\n",
       " 'qrmxoe',\n",
       " 'qrmxos',\n",
       " 'qrmoty',\n",
       " 'qrmoti',\n",
       " 'qrmotn',\n",
       " 'qrmote',\n",
       " 'qrmots',\n",
       " 'qrmomy',\n",
       " 'qrmomi',\n",
       " 'qrmomn',\n",
       " 'qrmome',\n",
       " 'qrmoms',\n",
       " 'qrmony',\n",
       " 'qrmoni',\n",
       " 'qrmonn',\n",
       " 'qrmone',\n",
       " 'qrmons',\n",
       " 'qrmoxy',\n",
       " 'qrmoxi',\n",
       " 'qrmoxn',\n",
       " 'qrmoxe',\n",
       " 'qrmoxs',\n",
       " 'qrmooy',\n",
       " 'qrmooi',\n",
       " 'qrmoon',\n",
       " 'qrmooe',\n",
       " 'qrmoos',\n",
       " 'qritty',\n",
       " 'qritti',\n",
       " 'qrittn',\n",
       " 'qritte',\n",
       " 'qritts',\n",
       " 'qritmy',\n",
       " 'qritmi',\n",
       " 'qritmn',\n",
       " 'qritme',\n",
       " 'qritms',\n",
       " 'qritny',\n",
       " 'qritni',\n",
       " 'qritnn',\n",
       " 'qritne',\n",
       " 'qritns',\n",
       " 'qritxy',\n",
       " 'qritxi',\n",
       " 'qritxn',\n",
       " 'qritxe',\n",
       " 'qritxs',\n",
       " 'qritoy',\n",
       " 'qritoi',\n",
       " 'qriton',\n",
       " 'qritoe',\n",
       " 'qritos',\n",
       " 'qrimty',\n",
       " 'qrimti',\n",
       " 'qrimtn',\n",
       " 'qrimte',\n",
       " 'qrimts',\n",
       " 'qrimmy',\n",
       " 'qrimmi',\n",
       " 'qrimmn',\n",
       " 'qrimme',\n",
       " 'qrimms',\n",
       " 'qrimny',\n",
       " 'qrimni',\n",
       " 'qrimnn',\n",
       " 'qrimne',\n",
       " 'qrimns',\n",
       " 'qrimxy',\n",
       " 'qrimxi',\n",
       " 'qrimxn',\n",
       " 'qrimxe',\n",
       " 'qrimxs',\n",
       " 'qrimoy',\n",
       " 'qrimoi',\n",
       " 'qrimon',\n",
       " 'qrimoe',\n",
       " 'qrimos',\n",
       " 'qriqty',\n",
       " 'qriqti',\n",
       " 'qriqtn',\n",
       " 'qriqte',\n",
       " 'qriqts',\n",
       " 'qriqmy',\n",
       " 'qriqmi',\n",
       " 'qriqmn',\n",
       " 'qriqme',\n",
       " 'qriqms',\n",
       " 'qriqny',\n",
       " 'qriqni',\n",
       " 'qriqnn',\n",
       " 'qriqne',\n",
       " 'qriqns',\n",
       " 'qriqxy',\n",
       " 'qriqxi',\n",
       " 'qriqxn',\n",
       " 'qriqxe',\n",
       " 'qriqxs',\n",
       " 'qriqoy',\n",
       " 'qriqoi',\n",
       " 'qriqon',\n",
       " 'qriqoe',\n",
       " 'qriqos',\n",
       " 'qrixty',\n",
       " 'qrixti',\n",
       " 'qrixtn',\n",
       " 'qrixte',\n",
       " 'qrixts',\n",
       " 'qrixmy',\n",
       " 'qrixmi',\n",
       " 'qrixmn',\n",
       " 'qrixme',\n",
       " 'qrixms',\n",
       " 'qrixny',\n",
       " 'qrixni',\n",
       " 'qrixnn',\n",
       " 'qrixne',\n",
       " 'qrixns',\n",
       " 'qrixxy',\n",
       " 'qrixxi',\n",
       " 'qrixxn',\n",
       " 'qrixxe',\n",
       " 'qrixxs',\n",
       " 'qrixoy',\n",
       " 'qrixoi',\n",
       " 'qrixon',\n",
       " 'qrixoe',\n",
       " 'qrixos',\n",
       " 'qrioty',\n",
       " 'qrioti',\n",
       " 'qriotn',\n",
       " 'qriote',\n",
       " 'qriots',\n",
       " 'qriomy',\n",
       " 'qriomi',\n",
       " 'qriomn',\n",
       " 'qriome',\n",
       " 'qrioms',\n",
       " 'qriony',\n",
       " 'qrioni',\n",
       " 'qrionn',\n",
       " 'qrione',\n",
       " 'qrions',\n",
       " 'qrioxy',\n",
       " 'qrioxi',\n",
       " 'qrioxn',\n",
       " 'qrioxe',\n",
       " 'qrioxs',\n",
       " 'qriooy',\n",
       " 'qriooi',\n",
       " 'qrioon',\n",
       " 'qriooe',\n",
       " 'qrioos',\n",
       " 'qrktty',\n",
       " 'qrktti',\n",
       " 'qrkttn',\n",
       " 'qrktte',\n",
       " 'qrktts',\n",
       " 'qrktmy',\n",
       " 'qrktmi',\n",
       " 'qrktmn',\n",
       " 'qrktme',\n",
       " 'qrktms',\n",
       " 'qrktny',\n",
       " 'qrktni',\n",
       " 'qrktnn',\n",
       " 'qrktne',\n",
       " 'qrktns',\n",
       " 'qrktxy',\n",
       " 'qrktxi',\n",
       " 'qrktxn',\n",
       " 'qrktxe',\n",
       " 'qrktxs',\n",
       " 'qrktoy',\n",
       " 'qrktoi',\n",
       " 'qrkton',\n",
       " 'qrktoe',\n",
       " 'qrktos',\n",
       " 'qrkmty',\n",
       " 'qrkmti',\n",
       " 'qrkmtn',\n",
       " 'qrkmte',\n",
       " 'qrkmts',\n",
       " 'qrkmmy',\n",
       " 'qrkmmi',\n",
       " 'qrkmmn',\n",
       " 'qrkmme',\n",
       " 'qrkmms',\n",
       " 'qrkmny',\n",
       " 'qrkmni',\n",
       " 'qrkmnn',\n",
       " 'qrkmne',\n",
       " 'qrkmns',\n",
       " 'qrkmxy',\n",
       " 'qrkmxi',\n",
       " 'qrkmxn',\n",
       " 'qrkmxe',\n",
       " 'qrkmxs',\n",
       " 'qrkmoy',\n",
       " 'qrkmoi',\n",
       " 'qrkmon',\n",
       " 'qrkmoe',\n",
       " 'qrkmos',\n",
       " 'qrkqty',\n",
       " 'qrkqti',\n",
       " 'qrkqtn',\n",
       " 'qrkqte',\n",
       " 'qrkqts',\n",
       " 'qrkqmy',\n",
       " 'qrkqmi',\n",
       " 'qrkqmn',\n",
       " 'qrkqme',\n",
       " 'qrkqms',\n",
       " 'qrkqny',\n",
       " 'qrkqni',\n",
       " 'qrkqnn',\n",
       " 'qrkqne',\n",
       " 'qrkqns',\n",
       " 'qrkqxy',\n",
       " 'qrkqxi',\n",
       " 'qrkqxn',\n",
       " 'qrkqxe',\n",
       " 'qrkqxs',\n",
       " 'qrkqoy',\n",
       " 'qrkqoi',\n",
       " 'qrkqon',\n",
       " 'qrkqoe',\n",
       " 'qrkqos',\n",
       " 'qrkxty',\n",
       " 'qrkxti',\n",
       " 'qrkxtn',\n",
       " 'qrkxte',\n",
       " 'qrkxts',\n",
       " 'qrkxmy',\n",
       " 'qrkxmi',\n",
       " 'qrkxmn',\n",
       " 'qrkxme',\n",
       " 'qrkxms',\n",
       " 'qrkxny',\n",
       " 'qrkxni',\n",
       " 'qrkxnn',\n",
       " 'qrkxne',\n",
       " 'qrkxns',\n",
       " 'qrkxxy',\n",
       " 'qrkxxi',\n",
       " 'qrkxxn',\n",
       " 'qrkxxe',\n",
       " 'qrkxxs',\n",
       " 'qrkxoy',\n",
       " 'qrkxoi',\n",
       " 'qrkxon',\n",
       " 'qrkxoe',\n",
       " 'qrkxos',\n",
       " 'qrkoty',\n",
       " 'qrkoti',\n",
       " 'qrkotn',\n",
       " 'qrkote',\n",
       " 'qrkots',\n",
       " 'qrkomy',\n",
       " 'qrkomi',\n",
       " 'qrkomn',\n",
       " 'qrkome',\n",
       " 'qrkoms',\n",
       " 'qrkony',\n",
       " 'qrkoni',\n",
       " 'qrkonn',\n",
       " 'qrkone',\n",
       " 'qrkons',\n",
       " 'qrkoxy',\n",
       " 'qrkoxi',\n",
       " 'qrkoxn',\n",
       " 'qrkoxe',\n",
       " 'qrkoxs',\n",
       " 'qrkooy',\n",
       " 'qrkooi',\n",
       " 'qrkoon',\n",
       " 'qrkooe',\n",
       " 'qrkoos',\n",
       " 'qrntty',\n",
       " 'qrntti',\n",
       " 'qrnttn',\n",
       " 'qrntte',\n",
       " 'qrntts',\n",
       " 'qrntmy',\n",
       " 'qrntmi',\n",
       " 'qrntmn',\n",
       " 'qrntme',\n",
       " 'qrntms',\n",
       " 'qrntny',\n",
       " 'qrntni',\n",
       " 'qrntnn',\n",
       " 'qrntne',\n",
       " 'qrntns',\n",
       " 'qrntxy',\n",
       " 'qrntxi',\n",
       " 'qrntxn',\n",
       " 'qrntxe',\n",
       " 'qrntxs',\n",
       " 'qrntoy',\n",
       " 'qrntoi',\n",
       " 'qrnton',\n",
       " 'qrntoe',\n",
       " 'qrntos',\n",
       " 'qrnmty',\n",
       " 'qrnmti',\n",
       " 'qrnmtn',\n",
       " 'qrnmte',\n",
       " 'qrnmts',\n",
       " 'qrnmmy',\n",
       " 'qrnmmi',\n",
       " 'qrnmmn',\n",
       " 'qrnmme',\n",
       " 'qrnmms',\n",
       " 'qrnmny',\n",
       " 'qrnmni',\n",
       " 'qrnmnn',\n",
       " 'qrnmne',\n",
       " 'qrnmns',\n",
       " 'qrnmxy',\n",
       " 'qrnmxi',\n",
       " 'qrnmxn',\n",
       " 'qrnmxe',\n",
       " 'qrnmxs',\n",
       " 'qrnmoy',\n",
       " 'qrnmoi',\n",
       " 'qrnmon',\n",
       " 'qrnmoe',\n",
       " 'qrnmos',\n",
       " 'qrnqty',\n",
       " 'qrnqti',\n",
       " 'qrnqtn',\n",
       " 'qrnqte',\n",
       " 'qrnqts',\n",
       " 'qrnqmy',\n",
       " 'qrnqmi',\n",
       " 'qrnqmn',\n",
       " 'qrnqme',\n",
       " 'qrnqms',\n",
       " 'qrnqny',\n",
       " 'qrnqni',\n",
       " 'qrnqnn',\n",
       " 'qrnqne',\n",
       " 'qrnqns',\n",
       " 'qrnqxy',\n",
       " 'qrnqxi',\n",
       " 'qrnqxn',\n",
       " 'qrnqxe',\n",
       " 'qrnqxs',\n",
       " 'qrnqoy',\n",
       " 'qrnqoi',\n",
       " 'qrnqon',\n",
       " 'qrnqoe',\n",
       " 'qrnqos',\n",
       " 'qrnxty',\n",
       " 'qrnxti',\n",
       " 'qrnxtn',\n",
       " 'qrnxte',\n",
       " 'qrnxts',\n",
       " 'qrnxmy',\n",
       " 'qrnxmi',\n",
       " 'qrnxmn',\n",
       " 'qrnxme',\n",
       " 'qrnxms',\n",
       " 'qrnxny',\n",
       " 'qrnxni',\n",
       " 'qrnxnn',\n",
       " 'qrnxne',\n",
       " 'qrnxns',\n",
       " 'qrnxxy',\n",
       " 'qrnxxi',\n",
       " 'qrnxxn',\n",
       " 'qrnxxe',\n",
       " 'qrnxxs',\n",
       " 'qrnxoy',\n",
       " 'qrnxoi',\n",
       " 'qrnxon',\n",
       " 'qrnxoe',\n",
       " 'qrnxos',\n",
       " 'qrnoty',\n",
       " 'qrnoti',\n",
       " 'qrnotn',\n",
       " 'qrnote',\n",
       " 'qrnots',\n",
       " 'qrnomy',\n",
       " 'qrnomi',\n",
       " 'qrnomn',\n",
       " 'qrnome',\n",
       " 'qrnoms',\n",
       " 'qrnony',\n",
       " 'qrnoni',\n",
       " 'qrnonn',\n",
       " 'qrnone',\n",
       " 'qrnons',\n",
       " 'qrnoxy',\n",
       " 'qrnoxi',\n",
       " 'qrnoxn',\n",
       " 'qrnoxe',\n",
       " 'qrnoxs',\n",
       " 'qrnooy',\n",
       " 'qrnooi',\n",
       " 'qrnoon',\n",
       " 'qrnooe',\n",
       " 'qrnoos',\n",
       " 'qmetty',\n",
       " 'qmetti',\n",
       " 'qmettn',\n",
       " 'qmette',\n",
       " 'qmetts',\n",
       " 'qmetmy',\n",
       " 'qmetmi',\n",
       " 'qmetmn',\n",
       " 'qmetme',\n",
       " 'qmetms',\n",
       " 'qmetny',\n",
       " 'qmetni',\n",
       " 'qmetnn',\n",
       " 'qmetne',\n",
       " 'qmetns',\n",
       " 'qmetxy',\n",
       " 'qmetxi',\n",
       " 'qmetxn',\n",
       " 'qmetxe',\n",
       " 'qmetxs',\n",
       " 'qmetoy',\n",
       " 'qmetoi',\n",
       " 'qmeton',\n",
       " 'qmetoe',\n",
       " 'qmetos',\n",
       " 'qmemty',\n",
       " 'qmemti',\n",
       " 'qmemtn',\n",
       " 'qmemte',\n",
       " 'qmemts',\n",
       " 'qmemmy',\n",
       " 'qmemmi',\n",
       " 'qmemmn',\n",
       " 'qmemme',\n",
       " 'qmemms',\n",
       " 'qmemny',\n",
       " 'qmemni',\n",
       " 'qmemnn',\n",
       " 'qmemne',\n",
       " 'qmemns',\n",
       " 'qmemxy',\n",
       " 'qmemxi',\n",
       " 'qmemxn',\n",
       " 'qmemxe',\n",
       " 'qmemxs',\n",
       " 'qmemoy',\n",
       " 'qmemoi',\n",
       " 'qmemon',\n",
       " 'qmemoe',\n",
       " 'qmemos',\n",
       " 'qmeqty',\n",
       " 'qmeqti',\n",
       " 'qmeqtn',\n",
       " 'qmeqte',\n",
       " 'qmeqts',\n",
       " 'qmeqmy',\n",
       " 'qmeqmi',\n",
       " 'qmeqmn',\n",
       " 'qmeqme',\n",
       " 'qmeqms',\n",
       " 'qmeqny',\n",
       " 'qmeqni',\n",
       " 'qmeqnn',\n",
       " 'qmeqne',\n",
       " 'qmeqns',\n",
       " 'qmeqxy',\n",
       " 'qmeqxi',\n",
       " 'qmeqxn',\n",
       " 'qmeqxe',\n",
       " 'qmeqxs',\n",
       " 'qmeqoy',\n",
       " 'qmeqoi',\n",
       " 'qmeqon',\n",
       " 'qmeqoe',\n",
       " 'qmeqos',\n",
       " 'qmexty',\n",
       " 'qmexti',\n",
       " 'qmextn',\n",
       " 'qmexte',\n",
       " 'qmexts',\n",
       " 'qmexmy',\n",
       " 'qmexmi',\n",
       " 'qmexmn',\n",
       " 'qmexme',\n",
       " 'qmexms',\n",
       " 'qmexny',\n",
       " 'qmexni',\n",
       " 'qmexnn',\n",
       " 'qmexne',\n",
       " 'qmexns',\n",
       " 'qmexxy',\n",
       " 'qmexxi',\n",
       " 'qmexxn',\n",
       " 'qmexxe',\n",
       " 'qmexxs',\n",
       " 'qmexoy',\n",
       " 'qmexoi',\n",
       " 'qmexon',\n",
       " 'qmexoe',\n",
       " 'qmexos',\n",
       " 'qmeoty',\n",
       " 'qmeoti',\n",
       " 'qmeotn',\n",
       " 'qmeote',\n",
       " 'qmeots',\n",
       " 'qmeomy',\n",
       " 'qmeomi',\n",
       " 'qmeomn',\n",
       " 'qmeome',\n",
       " 'qmeoms',\n",
       " 'qmeony',\n",
       " 'qmeoni',\n",
       " 'qmeonn',\n",
       " 'qmeone',\n",
       " 'qmeons',\n",
       " 'qmeoxy',\n",
       " 'qmeoxi',\n",
       " 'qmeoxn',\n",
       " 'qmeoxe',\n",
       " 'qmeoxs',\n",
       " 'qmeooy',\n",
       " 'qmeooi',\n",
       " 'qmeoon',\n",
       " 'qmeooe',\n",
       " 'qmeoos',\n",
       " 'qmmtty',\n",
       " 'qmmtti',\n",
       " 'qmmttn',\n",
       " 'qmmtte',\n",
       " 'qmmtts',\n",
       " 'qmmtmy',\n",
       " 'qmmtmi',\n",
       " 'qmmtmn',\n",
       " 'qmmtme',\n",
       " 'qmmtms',\n",
       " 'qmmtny',\n",
       " 'qmmtni',\n",
       " 'qmmtnn',\n",
       " 'qmmtne',\n",
       " 'qmmtns',\n",
       " 'qmmtxy',\n",
       " 'qmmtxi',\n",
       " 'qmmtxn',\n",
       " 'qmmtxe',\n",
       " 'qmmtxs',\n",
       " 'qmmtoy',\n",
       " 'qmmtoi',\n",
       " 'qmmton',\n",
       " 'qmmtoe',\n",
       " 'qmmtos',\n",
       " 'qmmmty',\n",
       " 'qmmmti',\n",
       " 'qmmmtn',\n",
       " 'qmmmte',\n",
       " 'qmmmts',\n",
       " 'qmmmmy',\n",
       " 'qmmmmi',\n",
       " 'qmmmmn',\n",
       " 'qmmmme',\n",
       " 'qmmmms',\n",
       " 'qmmmny',\n",
       " 'qmmmni',\n",
       " 'qmmmnn',\n",
       " 'qmmmne',\n",
       " 'qmmmns',\n",
       " 'qmmmxy',\n",
       " 'qmmmxi',\n",
       " 'qmmmxn',\n",
       " 'qmmmxe',\n",
       " 'qmmmxs',\n",
       " 'qmmmoy',\n",
       " 'qmmmoi',\n",
       " 'qmmmon',\n",
       " 'qmmmoe',\n",
       " 'qmmmos',\n",
       " 'qmmqty',\n",
       " 'qmmqti',\n",
       " 'qmmqtn',\n",
       " 'qmmqte',\n",
       " 'qmmqts',\n",
       " 'qmmqmy',\n",
       " 'qmmqmi',\n",
       " 'qmmqmn',\n",
       " 'qmmqme',\n",
       " 'qmmqms',\n",
       " 'qmmqny',\n",
       " 'qmmqni',\n",
       " 'qmmqnn',\n",
       " 'qmmqne',\n",
       " 'qmmqns',\n",
       " 'qmmqxy',\n",
       " 'qmmqxi',\n",
       " 'qmmqxn',\n",
       " 'qmmqxe',\n",
       " 'qmmqxs',\n",
       " 'qmmqoy',\n",
       " 'qmmqoi',\n",
       " 'qmmqon',\n",
       " 'qmmqoe',\n",
       " 'qmmqos',\n",
       " 'qmmxty',\n",
       " 'qmmxti',\n",
       " 'qmmxtn',\n",
       " 'qmmxte',\n",
       " 'qmmxts',\n",
       " 'qmmxmy',\n",
       " 'qmmxmi',\n",
       " 'qmmxmn',\n",
       " 'qmmxme',\n",
       " 'qmmxms',\n",
       " 'qmmxny',\n",
       " 'qmmxni',\n",
       " 'qmmxnn',\n",
       " 'qmmxne',\n",
       " 'qmmxns',\n",
       " 'qmmxxy',\n",
       " 'qmmxxi',\n",
       " 'qmmxxn',\n",
       " 'qmmxxe',\n",
       " 'qmmxxs',\n",
       " 'qmmxoy',\n",
       " 'qmmxoi',\n",
       " 'qmmxon',\n",
       " 'qmmxoe',\n",
       " 'qmmxos',\n",
       " 'qmmoty',\n",
       " 'qmmoti',\n",
       " 'qmmotn',\n",
       " 'qmmote',\n",
       " 'qmmots',\n",
       " 'qmmomy',\n",
       " 'qmmomi',\n",
       " 'qmmomn',\n",
       " 'qmmome',\n",
       " 'qmmoms',\n",
       " 'qmmony',\n",
       " 'qmmoni',\n",
       " 'qmmonn',\n",
       " 'qmmone',\n",
       " 'qmmons',\n",
       " 'qmmoxy',\n",
       " 'qmmoxi',\n",
       " 'qmmoxn',\n",
       " 'qmmoxe',\n",
       " 'qmmoxs',\n",
       " 'qmmooy',\n",
       " 'qmmooi',\n",
       " 'qmmoon',\n",
       " 'qmmooe',\n",
       " 'qmmoos',\n",
       " 'qmitty',\n",
       " 'qmitti',\n",
       " 'qmittn',\n",
       " 'qmitte',\n",
       " 'qmitts',\n",
       " 'qmitmy',\n",
       " 'qmitmi',\n",
       " 'qmitmn',\n",
       " 'qmitme',\n",
       " 'qmitms',\n",
       " 'qmitny',\n",
       " 'qmitni',\n",
       " 'qmitnn',\n",
       " 'qmitne',\n",
       " 'qmitns',\n",
       " 'qmitxy',\n",
       " 'qmitxi',\n",
       " 'qmitxn',\n",
       " 'qmitxe',\n",
       " 'qmitxs',\n",
       " 'qmitoy',\n",
       " 'qmitoi',\n",
       " 'qmiton',\n",
       " 'qmitoe',\n",
       " 'qmitos',\n",
       " 'qmimty',\n",
       " 'qmimti',\n",
       " 'qmimtn',\n",
       " 'qmimte',\n",
       " 'qmimts',\n",
       " 'qmimmy',\n",
       " 'qmimmi',\n",
       " 'qmimmn',\n",
       " 'qmimme',\n",
       " 'qmimms',\n",
       " 'qmimny',\n",
       " 'qmimni',\n",
       " 'qmimnn',\n",
       " 'qmimne',\n",
       " 'qmimns',\n",
       " 'qmimxy',\n",
       " 'qmimxi',\n",
       " 'qmimxn',\n",
       " 'qmimxe',\n",
       " 'qmimxs',\n",
       " 'qmimoy',\n",
       " 'qmimoi',\n",
       " 'qmimon',\n",
       " 'qmimoe',\n",
       " 'qmimos',\n",
       " 'qmiqty',\n",
       " 'qmiqti',\n",
       " 'qmiqtn',\n",
       " 'qmiqte',\n",
       " 'qmiqts',\n",
       " 'qmiqmy',\n",
       " 'qmiqmi',\n",
       " 'qmiqmn',\n",
       " 'qmiqme',\n",
       " 'qmiqms',\n",
       " 'qmiqny',\n",
       " 'qmiqni',\n",
       " 'qmiqnn',\n",
       " 'qmiqne',\n",
       " 'qmiqns',\n",
       " 'qmiqxy',\n",
       " 'qmiqxi',\n",
       " 'qmiqxn',\n",
       " 'qmiqxe',\n",
       " 'qmiqxs',\n",
       " 'qmiqoy',\n",
       " 'qmiqoi',\n",
       " 'qmiqon',\n",
       " 'qmiqoe',\n",
       " 'qmiqos',\n",
       " 'qmixty',\n",
       " 'qmixti',\n",
       " 'qmixtn',\n",
       " 'qmixte',\n",
       " 'qmixts',\n",
       " 'qmixmy',\n",
       " 'qmixmi',\n",
       " 'qmixmn',\n",
       " 'qmixme',\n",
       " 'qmixms',\n",
       " 'qmixny',\n",
       " 'qmixni',\n",
       " 'qmixnn',\n",
       " 'qmixne',\n",
       " 'qmixns',\n",
       " 'qmixxy',\n",
       " 'qmixxi',\n",
       " 'qmixxn',\n",
       " 'qmixxe',\n",
       " 'qmixxs',\n",
       " 'qmixoy',\n",
       " 'qmixoi',\n",
       " 'qmixon',\n",
       " 'qmixoe',\n",
       " 'qmixos',\n",
       " 'qmioty',\n",
       " 'qmioti',\n",
       " 'qmiotn',\n",
       " 'qmiote',\n",
       " 'qmiots',\n",
       " 'qmiomy',\n",
       " 'qmiomi',\n",
       " 'qmiomn',\n",
       " 'qmiome',\n",
       " 'qmioms',\n",
       " 'qmiony',\n",
       " 'qmioni',\n",
       " 'qmionn',\n",
       " 'qmione',\n",
       " 'qmions',\n",
       " 'qmioxy',\n",
       " 'qmioxi',\n",
       " 'qmioxn',\n",
       " 'qmioxe',\n",
       " 'qmioxs',\n",
       " 'qmiooy',\n",
       " 'qmiooi',\n",
       " 'qmioon',\n",
       " 'qmiooe',\n",
       " 'qmioos',\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creates a list of corpus from all the possibilites of the above classified data.\n",
    "\n",
    "list_output = list(itertools.product(*probable_output))\n",
    "string_output = []\n",
    "for x in list_output:\n",
    "    string = ''.join(x)\n",
    "    string_output.append(string.lower())\n",
    "string_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the output to a file to be read later by the language model.\n",
    "\n",
    "f = open(\"img_class_output.txt\",\"w\")\n",
    "\n",
    "for string in string_output:\n",
    "    f.write(\"%s\\n\" % string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15625"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
